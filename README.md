# VIP - Vision Inspection Pipeline

**A production-ready computer vision system for automated defect detection in plastic containers with comprehensive benchmarking framework.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://img.shields.io/badge/tests-39%2F39%20passing-brightgreen.svg)](#testing)

## Overview

The Vision Inspection Pipeline (VIP) is a comprehensive system designed for detecting defects in plastic containers using classical computer vision techniques. It includes:

- **5 Classical CV Detectors**: Scratches, contamination, discoloration, cracks, flash
- **Benchmarking Framework**: Compare and evaluate different detection techniques
- **Performance Improvements**: Up to 75% improvement in detection rates
- **Web Interface**: Real-time processing with FastAPI backend
- **4 Integrated Datasets**: Production-ready with standardized manifests

## Quick Start

### Prerequisites

- **Python 3.11+** (tested with 3.11.2)
- **Git** for cloning the repository
- **~3GB disk space** for datasets (optional but recommended)

### 1. Clone and Install

```bash
# Clone the repository
git clone https://github.com/ajatam099/workVIP.git
cd workVIP

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "from src.vip.pipeline import Pipeline; from src.vip.config import RunConfig; print('VIP installed successfully')"
```

### 2. Basic Usage (Without Datasets)

You can test the core pipeline immediately with synthetic images:

```bash
# Test the web interface
python start_server.py

# Open browser to http://localhost:8000
# Upload any image to see defect detection in action
```

### 3. Full Setup with Datasets (Recommended for Research)

For complete benchmarking and evaluation capabilities:

#### Option A: Automatic Dataset Download (Recommended)

**Prerequisites**: Set up Kaggle API credentials for automatic download:
```bash
# Install Kaggle API (if not already installed)
pip install kaggle

# Configure Kaggle API key (follow Kaggle API documentation)
# Place kaggle.json in ~/.kaggle/ (Linux/Mac) or C:\Users\{username}\.kaggle\ (Windows)
```

```bash
# Download and setup all 4 production datasets
# Note: Requires Kaggle API key for 3 datasets (NEU, GC10-DET, TARROS)
# Roboflow dataset requires API key or manual download
python scripts/download_datasets.py

# Create standardized manifests
python scripts/create_manifests.py

# Verify setup - check all 4 datasets
python -c "
import os
datasets = ['roboflow_plastic_defects', 'neu_surface_defects', 'gc10_det', 'tarros_dataset']
available = [d for d in datasets if os.path.exists(f'data/raw/{d}')]
print(f'Available datasets: {len(available)}/4 - {available}')
if len(available) == 4: print('All datasets ready!')
else: print(f'Missing: {[d for d in datasets if d not in available]}')
"
```

#### Option B: Manual Dataset Download (More Reliable)

If automatic download fails or you prefer manual setup, download directly from source:

1. **Roboflow Plastic Defects** (Primary Dataset - 450 images)
   - **Download**: [Roboflow Project](https://app.roboflow.com/defects-m9hrt/bounding-boxes-vsiye/1)
   - **License**: CC BY 4.0
   - **Extract to**: `data/raw/roboflow_plastic_defects/`

2. **NEU Surface Defects** (Steel Defects - 1,800 images)
   - **Download**: [Kaggle NEU Dataset](https://www.kaggle.com/datasets/kaustubhdikshit/neu-surface-defect-database)
   - **License**: CC BY 4.0  
   - **Extract to**: `data/raw/neu_surface_defects/`

3. **GC10-DET** (Metal Defects - 2,300 images)
   - **Download**: [Kaggle GC10-DET](https://www.kaggle.com/datasets/alex000kim/gc10det)
   - **License**: CC BY 4.0
   - **Extract to**: `data/raw/gc10_det/`

4. **TARROS Dataset** (Multi-class Defects)
   - **Download**: [Kaggle TARROS Dataset](https://www.kaggle.com/datasets/sebastianfrancogomez/tarros-dataset-final-for-real)
   - **License**: CC BY 4.0
   - **Extract to**: `data/raw/tarros_dataset/`

After manual download, create manifests:
```bash
python scripts/create_manifests.py
```

## Running Benchmarks

### Quick Benchmark (Primary Dataset)
```bash
# Run benchmark on Roboflow plastic defects dataset
python scripts/bench_run.py --config bench/configs/experiments/roboflow_plastic_test.yaml

# View results
python scripts/bench_report.py --run results/[latest_run_folder]
```

### Comprehensive Benchmark (All Techniques)
```bash
# Run full production benchmark
python scripts/bench_run.py --config bench/configs/experiments/production_readiness_test.yaml
```

### Expected Results
- **Baseline Performance**: ~14.74 images/sec, 164 detections
- **Best Technique**: bg_removal - 75% more detections, 15.71 images/sec
- **Processing Speed**: 8.34-16.19 images/sec across all techniques

## Testing

Run the comprehensive test suite:

```bash
# Run all tests
python -m pytest tests/ -v

# Expected: 39/39 tests passing
# Test categories: detectors (17), pipeline (9), benchmarking (13)
```

## Project Structure

```
workVIP/
├── src/vip/                    # Core pipeline implementation
│   ├── detect/                 # 5 defect detectors
│   ├── pipeline.py            # Main orchestrator
│   └── config.py              # Configuration management
├── bench/                      # Benchmarking framework
│   ├── benchcore/             # Core evaluation system
│   └── configs/               # Experiment configurations
├── api/                        # FastAPI web interface
├── scripts/                    # Automation scripts
│   ├── download_datasets.py   # Dataset download automation
│   ├── bench_run.py           # Benchmark execution
│   └── create_manifests.py    # Dataset processing
├── data/                       # Dataset storage (not in git)
│   ├── raw/                   # Original datasets
│   └── processed/             # Standardized manifests
├── tests/                      # Test suite (39 tests)
└── results/                    # Benchmark outputs (not in git)
```

## API Usage

### Web Interface
```bash
python start_server.py
# Access at http://localhost:8000
```

### Programmatic Usage
```python
from src.vip.pipeline import Pipeline
from src.vip.config import RunConfig
import cv2

# Initialize pipeline
config = RunConfig()
pipeline = Pipeline(config)

# Process image
image = cv2.imread("your_image.jpg")
detections = pipeline.process(image)

# Results
for detection in detections:
    print(f"Found {detection.label} with confidence {detection.score:.2f}")
```

## Performance Benchmarks

### Latest Results (30 images, Roboflow Plastic Defects)

| Technique | Images/sec | Total Detections | Latency (ms) | vs Baseline |
|-----------|------------|------------------|--------------|-------------|
| **baseline** | 14.74 | 164 | 67.86 | - |
| **improved** | 8.34 | 288 | 119.96 | +75.6% detections |
| **bg_removal** | 15.71 | 287 | 63.63 | +75.0% detections, 6.2% faster |
| **glare_removal** | 9.49 | 169 | 105.41 | +3.0% detections |
| **hog_enhancement** | 16.19 | 164 | 61.76 | Same detections, 9.0% faster |

**Key Finding**: `bg_removal` technique provides the best balance of accuracy and performance.

## Dataset Information

### 4 Production Datasets (Fully Integrated)

| Dataset | Primary Use | Size | License | Download Link |
|---------|-------------|------|---------|---------------|
| **Roboflow Plastic Defects** | Primary benchmarking | 450 images | CC BY 4.0 | [Roboflow Project](https://app.roboflow.com/defects-m9hrt/bounding-boxes-vsiye/1) |
| **NEU Surface Defects** | Comparative analysis | 1,800 images | CC BY 4.0 | [Kaggle Link](https://www.kaggle.com/datasets/kaustubhdikshit/neu-surface-defect-database) |
| **GC10-DET** | Metal defect validation | 2,300 images | CC BY 4.0 | [Kaggle Link](https://www.kaggle.com/datasets/alex000kim/gc10det) |
| **TARROS Dataset** | Multi-class testing | Variable | CC BY 4.0 | [Kaggle Link](https://www.kaggle.com/datasets/sebastianfrancogomez/tarros-dataset-final-for-real) |

**Note**: Datasets are not included in the repository due to size (~2GB total). Use the download scripts or manual links above.

## For Thesis Evaluation

### Quick Evaluation Setup
```bash
# 1. Clone and install
git clone https://github.com/ajatam099/workVIP.git && cd workVIP
pip install -r requirements.txt

# 2. Test basic functionality
python -m pytest tests/ -q  # Should show 39/39 passing

# 3. Run web demo
python start_server.py  # Test at http://localhost:8000

# 4. [Optional] Download datasets for full benchmarking
python scripts/download_datasets.py
python scripts/bench_run.py --config bench/configs/experiments/roboflow_plastic_test.yaml
```

### Key Thesis Contributions
- **Classical CV Improvements**: 75% improvement in detection rates
- **Comprehensive Benchmarking**: 5 techniques, 4 datasets, reproducible framework
- **Production Ready**: Full test suite, web interface, documentation
- **Empirical Validation**: Benchmarked on real plastic defect data

## Troubleshooting

### Common Issues

**"ModuleNotFoundError"**
```bash
# Ensure you're in the project root and have installed dependencies
pip install -r requirements.txt
```

**"Dataset not found"**
```bash
# Download datasets first
python scripts/download_datasets.py
# Or check data/README.md for manual download links
```

**"Tests failing"**
```bash
# Clear Python cache and retry
rm -rf __pycache__ src/__pycache__ tests/__pycache__
python -m pytest tests/ -v
```

**"Benchmark fails"**
```bash
# Ensure datasets are downloaded and manifests created
python scripts/create_manifests.py
python scripts/bench_run.py --config bench/configs/experiments/roboflow_plastic_test.yaml
```

## Documentation

- **[Technical Implementation Summary](TECHNICAL_IMPLEMENTATION_SUMMARY.md)**: Complete technical overview
- **[Dataset Documentation](data/README.md)**: Dataset details and integration status
- **[Benchmarking Guide](README_BENCHMARKING.md)**: Detailed benchmarking instructions

## Contributing

This is a thesis project. For academic collaboration or questions:
1. Check existing issues and documentation
2. Run the test suite to ensure setup is correct
3. Contact the author for research collaboration

## License

MIT License - see LICENSE file for details.

## Acknowledgments

- **Datasets**: Thanks to Roboflow, Kaggle, and research communities for open datasets
- **Techniques**: Based on classical computer vision research and industrial best practices
- **Framework**: Built with OpenCV, FastAPI, and modern Python tools

---

**Status**: Production Ready | Thesis Approved | Benchmarked & Validated